"""
åˆ†ç±»å¢å¼ºè„šæœ¬
æ ¹æ®taxonomyä»£ç ä¸ºprovideræ•°æ®æ·»åŠ classificationå’Œspecializationä¿¡æ¯
"""

import pandas as pd
import os
import sys

# æ·»åŠ utilsæ¨¡å—åˆ°è·¯å¾„
sys.path.append(os.path.join(os.path.dirname(__file__), 'utils'))

from utils import (
    read_csv_full, log_progress, load_json, save_json_streaming,
    print_sample_record, ProgressTracker
)


def enrich_taxonomy():
    """
    ä½¿ç”¨taxonomyæ•°æ®å¢å¼ºproviderä¿¡æ¯
    """

    # æ–‡ä»¶è·¯å¾„é…ç½®
    taxonomy_file = r"D:\EMRTS\PROVIDER_LOOKUP\data\taxonomy\taxonomy.csv"
    input_file = r"D:\EMRTS\PROVIDER_LOOKUP\output\provider_with_endpoints.json"
    output_file = r"D:\EMRTS\PROVIDER_LOOKUP\output\provider_with_taxonomy.json"

    log_progress("å¼€å§‹taxonomyåˆ†ç±»å¢å¼º")

    # æ£€æŸ¥è¾“å…¥æ–‡ä»¶
    if not os.path.exists(input_file):
        log_progress(f"é”™è¯¯ï¼šè¾“å…¥æ•°æ®æ–‡ä»¶ä¸å­˜åœ¨: {input_file}")
        log_progress("è¯·å…ˆè¿è¡Œ 3_merge_endpoints.py")
        return False

    if not os.path.exists(taxonomy_file):
        log_progress(f"é”™è¯¯ï¼štaxonomyæ–‡ä»¶ä¸å­˜åœ¨: {taxonomy_file}")
        return False

    try:
        # 1. è¯»å–taxonomyæ•°æ®
        log_progress("æ­£åœ¨è¯»å–taxonomyæ•°æ®")
        taxonomy_df = read_csv_full(taxonomy_file, dtype={'Code': str})
        log_progress(f"Taxonomyæ•°æ®åŠ è½½å®Œæˆï¼Œå…± {len(taxonomy_df):,} æ¡è®°å½•")

        # æ˜¾ç¤ºtaxonomyæ–‡ä»¶çš„åˆ—å
        log_progress(f"Taxonomyæ–‡ä»¶åˆ—å: {list(taxonomy_df.columns)}")

        # æ£€æŸ¥å…³é”®åˆ—æ˜¯å¦å­˜åœ¨
        if 'Code' not in taxonomy_df.columns:
            log_progress("é”™è¯¯ï¼štaxonomyæ–‡ä»¶ç¼ºå°‘'Code'åˆ—")
            return False

        # æ™ºèƒ½æ£€æµ‹classificationå’Œspecializationåˆ—
        classification_col = None
        specialization_col = None

        for col in taxonomy_df.columns:
            col_lower = col.lower()
            if 'classification' in col_lower and not classification_col:
                classification_col = col
            elif ('specialization' in col_lower or 'specialty' in col_lower) and not specialization_col:
                specialization_col = col

        # å¦‚æœæ²¡æœ‰æ‰¾åˆ°ï¼Œä½¿ç”¨é»˜è®¤å‡è®¾
        if not classification_col and len(taxonomy_df.columns) >= 2:
            classification_col = taxonomy_df.columns[1]
            log_progress(f"ä½¿ç”¨ '{classification_col}' ä½œä¸ºclassificationåˆ—")

        if not specialization_col and len(taxonomy_df.columns) >= 3:
            specialization_col = taxonomy_df.columns[2]
            log_progress(f"ä½¿ç”¨ '{specialization_col}' ä½œä¸ºspecializationåˆ—")

        # åˆ›å»ºtaxonomyå­—å…¸ç”¨äºå¿«é€ŸæŸ¥æ‰¾
        log_progress("åˆ›å»ºtaxonomyæŸ¥æ‰¾å­—å…¸")
        taxonomy_dict = {}

        for _, row in taxonomy_df.iterrows():
            code = str(row['Code']).strip() if pd.notna(row['Code']) else ''
            if code:
                taxonomy_dict[code] = {
                    'classification': str(row[classification_col]).strip() if classification_col and pd.notna(
                        row[classification_col]) else '',
                    'specialization': str(row[specialization_col]).strip() if specialization_col and pd.notna(
                        row[specialization_col]) else ''
                }

        log_progress(f"Taxonomyå­—å…¸åˆ›å»ºå®Œæˆï¼Œå…± {len(taxonomy_dict):,} ä¸ªæœ‰æ•ˆä»£ç ")

        # 2. è¯»å–provideræ•°æ®
        provider_data = load_json(input_file)

        # 3. åˆå¹¶taxonomyä¿¡æ¯
        log_progress("æ­£åœ¨åˆå¹¶taxonomyä¿¡æ¯")

        tracker = ProgressTracker(len(provider_data), 100000, "åˆ†ç±»å¢å¼º")

        matched_count = 0
        unmatched_count = 0

        for record in provider_data:
            # è·å–primary_taxonomy_codeï¼Œå®‰å…¨å¤„ç†å„ç§æ•°æ®ç±»å‹
            taxonomy_code_raw = record.get('primary_taxonomy_code')

            if taxonomy_code_raw is None or taxonomy_code_raw == '' or (
                    isinstance(taxonomy_code_raw, float) and pd.isna(taxonomy_code_raw)):
                taxonomy_code = ''
            else:
                taxonomy_code = str(taxonomy_code_raw).strip()

            if taxonomy_code and taxonomy_code in taxonomy_dict:
                # æ‰¾åˆ°åŒ¹é…çš„taxonomyä¿¡æ¯
                taxonomy_info = taxonomy_dict[taxonomy_code]
                record['classification'] = taxonomy_info['classification']
                record['specialization'] = taxonomy_info['specialization']
                matched_count += 1
            else:
                # æ²¡æœ‰æ‰¾åˆ°åŒ¹é…çš„taxonomyä¿¡æ¯
                record['classification'] = ''
                record['specialization'] = ''
                unmatched_count += 1

            tracker.update()

        tracker.finish()

        log_progress(f"åˆ†ç±»å¢å¼ºå®Œæˆ:")
        log_progress(f"  åŒ¹é…æˆåŠŸ: {matched_count:,} æ¡è®°å½•")
        log_progress(f"  æœªåŒ¹é…: {unmatched_count:,} æ¡è®°å½•")
        log_progress(f"  åŒ¹é…ç‡: {(matched_count / len(provider_data) * 100):.2f}%")

        # 4. ä¿å­˜æœ€ç»ˆæ•°æ®
        save_json_streaming(provider_data, output_file)

        # æ˜¾ç¤ºç¤ºä¾‹è®°å½•
        sample_keys = ['npi', 'provider_name', 'primary_taxonomy_code', 'classification', 'specialization']
        print_sample_record(provider_data, sample_keys)

        log_progress("Taxonomyåˆ†ç±»å¢å¼ºå®Œæˆ")
        return True

    except Exception as e:
        log_progress(f"å¤„ç†è¿‡ç¨‹ä¸­å‡ºé”™: {e}")
        return False


if __name__ == "__main__":
    success = enrich_taxonomy()
    if success:
        print("\nâœ… Taxonomyåˆ†ç±»å¢å¼ºæˆåŠŸå®Œæˆï¼")
        print("è¾“å‡ºæ–‡ä»¶: D:\\EMRTS\\PROVIDER_LOOKUP\\output\\provider_with_taxonomy.json")
        print("ğŸ‰ æ‰€æœ‰æ•°æ®å¤„ç†æ­¥éª¤å·²å®Œæˆï¼")
    else:
        print("\nâŒ Taxonomyåˆ†ç±»å¢å¼ºå¤±è´¥")
        sys.exit(1)